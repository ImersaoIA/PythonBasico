{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml_class.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente, *machine learning*- ou  aprendizado de máquina - é o estudo que permite automatizar uma tarefa sem a intervenção direta de um humano, usando modelos para extrair as informações de bases de dados.\n",
    "\n",
    "No jargão, o modelo \"treina\" com base nos dados de entrada, e depois \"prevê\" resultados a medida que encontra novas situações.\n",
    "\n",
    "Os modelos podem ser:\n",
    "\n",
    "- **Supervisionados**: se o treino é realizado com a disponibilidade de variáveis respostas da base de treino\n",
    "- **Não-supervisionados**: se o próprio algortimo é capaz de extrair as relações relevantes e inferir a variável resposta. Geralmente utilizado em clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos e algoritmos\n",
    "\n",
    "Agora começamos algumas definições úteis\n",
    "\n",
    "- **Modelo**: entendemos aqui como a formulação matemática que relaciona as variáveis de entrada com a(s) variável(is) de saída.\n",
    "- **Algoritmo**: o processo matemático e estatítico usado para adequar - *fit* - o modelo aos dados.\n",
    "- **Métrica de sucesso**: índice que será usado na avaliação da qualidade do resultado. Depende do modelo utilizado\n",
    "- **Preprocessamento, ou *data prep***: preparação da base de dados para uso no algoritmo (selecionar/extrair variáveis, tratar valores faltantes, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=modelo.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Overfitting* e *Underfitting*\n",
    "\n",
    "Dois fenômenos, totalmente opostos e igualmente desastrosos, podem ocorrer aos se realizar o *fit* do modelo.\n",
    "\n",
    "- ***Overfitting***: quando o modelo acaba por se adequar *demais* dos dados de treino, como se o algortimo tivesse decorado que tal entrada tem tal saída. Resultados podem estar longe da realidade para pontos não utilizados no *fit*. Dizemos que o modelo tem alta **variância**.\n",
    "- ***Underfitting***: pelo contrário, quando o modelo quase não se adequa aos dados de treino. Dizemos que tem alto **viés**, pois apesar das informações apresentadas, pouco concede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=over_under.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada\n",
    "\n",
    "Uma maneira de contornar os problemas de *over* e *underfitting* é, em primeiro lugar, separar os dados em dois tipos: para treino e para teste. Assim temos maior controle quanto a qualidade do modelo nesse sentido.\n",
    "\n",
    "#### *Overfitting*:\n",
    "\n",
    "- **Característica**: Boa performance no *set* de treino, baixa no de teste.\n",
    "- **Causa**: muitas variáveis, modelo muito complexo\n",
    "- **Solução**: reduzir número de variáveis, regularização\\*, mais pontos\n",
    "\n",
    "#### *Underfitting*\n",
    "\n",
    "- **Característica**: Baixa performance tanto no *set* de treino quanto no de teste\n",
    "- **Causa**: modelo simples demais, muito rígido (regularização\\*)\n",
    "- **Solução**: mais variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=boston_data.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_boston()\n",
    "df = pd.DataFrame(x.data, columns = x.feature_names)\n",
    "df[\"MEDV\"] = x.target\n",
    "dfx = df.drop(\"MEDV\",1) \n",
    "dfy = df[\"MEDV\"]        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dfx)\n",
    "y = np.array(dfy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização\n",
    "\n",
    "Para evitar que variáveis com maior escala dominem a função custo, dado que uma variação nelas influenciariam mais o resultado, é necessário padronizar a escala de todos os *inputs* numéricos.\n",
    "\n",
    "Isso pode ser feito subtraindo o valor mínimo e dividindo pelo intervalo de variação:\n",
    "\n",
    "$$ x_p = \\frac{x - x_{mín}}{x_{máx} - x_{mín}}$$\n",
    "\n",
    "Ou subtraindo o valor médio e dividindo pela variância:\n",
    "\n",
    "$$ x_n = \\frac{x - \\bar{x}}{s_x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Feature Selection*\n",
    "\n",
    "É importante, então, decidir quais informações valem de fato a pena serem usadas no modelo\n",
    "\n",
    "Algumas formas principais de selecionar as variáveis:\n",
    "\n",
    "#### Filtro\n",
    "\n",
    "Seleciona variáveis com base na relação com a variável resposta. Independe do modelo\n",
    "\n",
    "<img src='filter.png'>\n",
    "\n",
    "#### Wrapper\n",
    "\n",
    "Utiliza o próprio modelo para determinar a importância das variáveis.\n",
    "\n",
    "<img src='wrapper.png'>\n",
    "\n",
    "#### Embedded\n",
    "\n",
    "Utiliza, além do modelo em si, a sua performance\n",
    "\n",
    "<img src='embedded.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear\n",
    "<br>\n",
    "<br>\n",
    "<img src=lin_reg.png width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulação\n",
    "\n",
    "Na regressão linear, representamos a relação entre as variáveis independentes e depentendes no seguinte modelo:\n",
    "\n",
    "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n + \\epsilon$$\n",
    "\n",
    "Ou, de forma matricial\n",
    "\n",
    "$$ y = \\Theta^{\\it{T}}X + \\epsilon$$\n",
    "\n",
    "Onde $\\Theta^{\\it{T}} = [\\theta_0\\hspace{1.5mm}\\theta_1 ... \\theta_n]\\hspace{1mm}$ e $\\hspace{1mm}X = [1\\hspace{1.5mm}x_1 ... x_n]^{\\it{T}}$, e $\\epsilon$ é o erro, que admitimos ter distribuição normal de média 0.\n",
    "\n",
    "Nota-se que o termo **linear** se refere à relação entre os coeficientes. Sendo assim, o modelo $ y = a_1x_1 +a_2x_1^2+ a_3\\log{x_1}$ é linear, pois basta substituir $x_2=x_1^2\\hspace{1mm}$ e $\\hspace{1mm}x_3=\\log{x_1}$\n",
    "\n",
    "#### Algoritmos\n",
    "\n",
    "Como definimos anteriormente, já temos o modelo, agora falta definir como encontrar os coeficientes que mais adequam esse modelo aos nossos dados. Como estamos falando de **modelos supervisionados**, basicamente cada algoritmo tentará minimizar uma **função custo**, que mensiona o quanto os pontos estimados $\\hat{y}$ estão divergentes dos pontos reais $y$.\n",
    "\n",
    "##### Mínimos Quadrados\n",
    "\n",
    "O mais simples dos algortimos, tem como função de custo a soma do quadrado das diferenças entre real e estimado, ou seja:\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 $$\n",
    "\n",
    "Prefere-se, assim, vários pequenos erros a alguns erros grandes. \n",
    "\n",
    "Como consequência, o algoritmo se torna relativamente sensível a *outliers*, pontos que por acaso de distanciam do comportamento normal, já que o custo cresce com o quadrado da distância.\n",
    "\n",
    "\n",
    "\n",
    "##### Ridge - Regularização $L_2$\n",
    "\n",
    "A regularização tem por objetivo limitar a exploração do algoritmo quanto ao espaço de soluções possíveis. No caso do que chamamos de regularização $L_2$, adicionamos o quadrado dos coeficientes à função custo:\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 + \\alpha\\sum_{i=0}^{N} |\\theta_i|^2 $$\n",
    "\n",
    "O novo termo enrigece a solução, pois aumentos nos coeficientes serão penalizados, o que aumenta o viés, podendo ser utilizao para remediar o problema de *overfitting*.\n",
    "\n",
    "Porém, mais um parâmetro deve ser definido: o valor de $\\alpha$ que traz o melhor comprometimento viés-variância para a qualidade do modelo - maior $\\alpha$ implica maior viés, sendo $\\alpha=0$ o equivalente aos Mínimos Quadrados. Uma solução é a criação de uma terceira partição nos dados, além de treino e teste.\n",
    "\n",
    "Com a primeira achamos o melhor $\\Theta$ dado $\\alpha$, a segunda usamos para definir o $\\alpha$ mais adequado, e a terceira nos dá a medida da qualidade do modelo em si. \n",
    "\n",
    "\n",
    "\n",
    "##### Lasso - Regularização $L_1$\n",
    "\n",
    "De forma semelhante ao **Ridge**, utiliza uma penalidade para os valores dos coeficientes, mas com a norma $l_1$. Sendo assim, este algoritmo costuma achar soluções em que os coeficientes das variáveis menos importantes são zerados. É comum usá-lo para selecionar variáveis.\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 + \\alpha\\sum_{i=0}^{N} |\\theta_i| $$\n",
    "\n",
    "Mesmas observações sobre o novo parâmetro $\\alpha$ no algoritmo anterior.\n",
    "<br>\n",
    "<img src='L1_L2.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "Para avaliar a qualidade do modelo, temos a nosso dispor algumas métricas. No caso de regressões, as mais comuns são:\n",
    "\n",
    "#### Variância explicada\n",
    "\n",
    "Como o nome diz, nos dá o quanto o modelo consegue explicar da variação que observamos nos dados:\n",
    "\n",
    "$$ VE(y,\\hat{y}) = 1-\\frac{Var(y-\\hat{y})}{Var(y)}$$\n",
    "\n",
    "#### Erro médio quadrado\n",
    "\n",
    "Média no quadrado da diferença entre real e estimado\n",
    "\n",
    "$$ EMQ = \\frac{\\sum_{j=1}^{M} (y-\\hat{y})^2}{M+1}$$\n",
    "\n",
    "#### Coeficiente de determinação - $R^2$\n",
    "\n",
    "Nos trás o quão bem amostras futuras devem ser estimadas\n",
    "\n",
    "$$ R^2=1-\\frac{\\sum_{j=0}^{M} (y-\\hat{y})^2}{\\sum_{j=0}^{M} (y-\\bar{y})^2}$$\n",
    "\n",
    "Notamos que $R^2$ é númericamente igual à variância explicada.\n",
    "\n",
    "#### R ajustado - $R_{adj}^2$ ou $\\bar{R^2}$\n",
    "\n",
    "O coeficiente de determinação $R^2$ tende a aumentar com a adição de variáveis, independentemente de sua relevância para o modelo. Sendo assim, ao se comparar soluções com número diferente de *inputs*, devemos usar o R ajustado, que tenta controlar esse efeito (M: número de pontos; N: número de variáveis): \n",
    "\n",
    "$$ \\bar{R^2}=1-(1-R^2)\\frac{M-1}{M-N-1}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def r2_aj (y_true, y_pred, shape):\n",
    "    R2 = r2_score(y_true, y_pred)\n",
    "    ra = 1-(1-R2)*(shape[0]-1)/(shape[0]-shape[1]-1)\n",
    "    return ra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "ln = LinearRegression()\n",
    "rd = Ridge(alpha=0.5)\n",
    "ls = Lasso(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regressão Linear\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lasso\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação\n",
    "\n",
    "Durante a decisão de escolha do modleo, é preciso ter controle da qualidade do que está sendo gerado. Se dependermos somente dos dados com que o algoritmo está treinando, corremos risco de *overfitting*, com muito erro ao se extrapolar para dados além do treino.\n",
    "\n",
    "A solução mais simples é simular dados desconhecidos ao modelo, separando parte da base de treino, a ser usada somente na sua validação.\n",
    "\n",
    "\n",
    "#### Hold-out\n",
    "\n",
    "Método mais simples, dividem-se os dados históricos em *dataset* de treino e de validação. Apesar de se medir a qualidade do *fit* nos dados de treino, as decisões são tomadas com base na validação.\n",
    "\n",
    "<img src=holdout.png>\n",
    "\n",
    "#### Validação cruzada\n",
    "\n",
    "Uma desvantagem do *hold-out* é a limitação que traz em termos de quantidade de pontos em que o modelo será treinado e validado. Se aumentarmos os pontos de treino, teremos menos pontos de validação, e vice-versa.\n",
    "\n",
    "Como alternativa, podemos repetir a divisão treino-teste até passar por toda base de dados, efetuando a validação a cada passo. A performance geral do modelo é obtida da média da performance em cada divisão.\n",
    "\n",
    "<img src=kfold.png>\n",
    "\n",
    "#### Bootstrap (re-amostragem)\n",
    "\n",
    "Com o *bootstrap*, um novo *dataset* é criado a partir de amostragens aleatórias - com reposição - dos dados que já temos.\n",
    "\n",
    "Os dados históricos são entendidos como uma amostra da distribuição real dos dados, e o processo de *bootstrapping* procura recriar esse efeito.\n",
    "\n",
    "<img src=bootstrap.png>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
