{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml_def.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente, *machine learning*- ou  aprendizado de máquina - é o estudo que permite automatizar uma tarefa sem a intervenção direta de um humano, usando modelos para extrair as informações de bases de dados.\n",
    "\n",
    "No jargão, o modelo \"treina\" com base nos dados de entrada, e depois \"prevê\" resultados a medida que encontra novas situações.\n",
    "\n",
    "Os modelos podem ser:\n",
    "\n",
    "- Supervisionados: se o treino é realizado com a disponibilidade de variáveis respostas da base de treino\n",
    "- Não-supervisionados: se o próprio algortimo é capaz de extrair as relações relevantes e inferir a variável resposta. Geralmente utilizado em clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos e algoritmos\n",
    "\n",
    "Agora começamos algumas definições úteis\n",
    "\n",
    "- Modelo: entendemos aqui como a formulação matemática que relaciona as variáveis de entrada com a(s) variável(is) de saída. Por exemplo, usaremos mais tarde o modelo $Y = \\omega_0 + \\omega_1 X$, onde X é uma matriz nxm com n pontos de m variáveis.\n",
    "- Algoritmo: o processo matemático e estatítico usado para adequar - *fit* - o modelo aos dados.\n",
    "- Métrica de sucesso: índice que será usado na avaliação da qualidade do resultado. Depende do modelo utilizado\n",
    "- Preprocessamento, ou *data prep*: preparação da base de dados para uso no algoritmo (selecionar/extrair variáveis, tratar valores faltantes, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Overfitting* e *Underfitting*\n",
    "\n",
    "Dois fenômenos, totalmente opostos e igualmente desastrosos, podem ocorrer aos se realizar o *fit* do modelo.\n",
    "\n",
    "- ***Overfitting***: quando o modelo acaba por se adequar *demais* dos dados de treino, como se o algortimo tivesse decorado que tal entrada tem tal saída. Resultados podem estar longe da realidade para pontos não utilizados no *fit*. Dizemos que o modelo tem alta **variância**.\n",
    "- ***Underfitting***: pelo contrário, quando o modelo quase não se adequa aos dados de treino. Dizemos que tem alto **viés**, pois apesar das informações apresentadas, pouco concede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=over_under.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada\n",
    "\n",
    "Uma maneira de contornar os problemas de *over* e *underfitting* é, em primeiro lugar, separar os dados em dois tipos: para treino e para teste. Assim temos maior controle quanto a qualidade do modelo nesse sentido.\n",
    "\n",
    "#### *Overfitting*:\n",
    "\n",
    "- **Característica**: Boa performance no *set* de treino, baixa no de teste.\n",
    "- **Causa**: muitas variáveis, modelo muito complexo\n",
    "- **Solução**: reduzir número de variáveis, regularização\\*, mais pontos\n",
    "\n",
    "#### *Underfitting*\n",
    "\n",
    "- **Característica**: Baixa performance tanto no *set* de treino quanto no de teste\n",
    "- **Causa**: modelo simples demais, muito rígido (regularização\\*)\n",
    "- **Solução**: mais variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Feature Selection*\n",
    "\n",
    "É importante, então, decidir quais informações valem de fato a pena serem usadas no modelo\n",
    "\n",
    "Algumas formas principais de selecionar as variáveis:\n",
    "\n",
    "#### Filtro\n",
    "\n",
    "Seleciona variáveis com base na relação com a variável resposta. Independe do modelo\n",
    "\n",
    "<img src='filter.png'>\n",
    "\n",
    "#### Wrapper\n",
    "\n",
    "Utiliza o próprio modelo para determinar a importância das variáveis.\n",
    "\n",
    "<img src='wrapper.png'>\n",
    "\n",
    "#### Embedded\n",
    "\n",
    "Utiliza, além do modelo em si, a sua performance\n",
    "\n",
    "<img src='embedded.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear\n",
    "<br>\n",
    "<br>\n",
    "<img src=linreg.png width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulação\n",
    "\n",
    "Na regressão linear, representamos a relação entre as variáveis independentes e depentendes no seguinte modelo:\n",
    "\n",
    "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n + \\epsilon$$\n",
    "\n",
    "Ou, de forma matricial\n",
    "\n",
    "$$ y = \\Theta^{\\it{T}}X + \\epsilon$$\n",
    "\n",
    "Onde $\\Theta^{\\it{T}} = [\\theta_0\\hspace{1.5mm}\\theta_1 ... \\theta_n]\\hspace{1mm}$ e $\\hspace{1mm}X = [1\\hspace{1.5mm}x_1 ... x_n]^{\\it{T}}$, e $\\epsilon$ é o erro, que admitimos ter distribuição normal de média 0.\n",
    "\n",
    "Nota-se que o termo **linear** se refere à relação entre os coeficientes. Sendo assim, o modelo $ y = a_1x_1 +a_2x_1^2+ a_3\\log{x_1}$ é linear, pois basta substituir $x_2=x_1^2\\hspace{1mm}$ e $\\hspace{1mm}x_3=\\log{x_1}$\n",
    "\n",
    "#### Algoritmos\n",
    "\n",
    "Como definimos anteriormente, já temos o modelo, agora falta definir como encontrar os coeficientes que mais adequam esse modelo aos nossos dados. Como estamos falando de **modelos supervisionados**, basicamente cada algoritmo tentará minimizar uma **função custo**, que mensiona o quanto os pontos estimados $\\hat{y}$ estão divergentes dos pontos reais $y$.\n",
    "\n",
    "##### Mínimos Quadrados\n",
    "\n",
    "O mais simples dos algortimos, tem como função de custo a soma do quadrado das diferenças entre real e estimado, ou seja:\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 $$\n",
    "\n",
    "Como consequência, o algoritmo se torna relativamente sensível a *outliers*, pontos que por acaso de distanciam do comportamento normal, já que o custo cresce com o quadrado da distância.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Ridge - Regularização $L_2$\n",
    "\n",
    "A regularização tem por objetivo limitar a exploração do algoritmo quanto ao espaço de soluções possíveis. No caso do que chamamos de regularização $L_2$, adicionamos o quadrado dos coeficientes à função custo:\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 + \\alpha\\sum_{i=0}^{N} |\\theta_i|^2 $$\n",
    "\n",
    "O novo termo enrigece a solução, pois aumentos nos coeficientes serão penalizados, o que aumenta o viés, podendo ser utilizao para remediar o problema de *overfitting*.\n",
    "\n",
    "Porém, mais um parâmetro deve ser definido: o valor de $\\alpha$ que traz o melhor comprometimento viés-variância para a qualidade do modelo - maior $\\alpha$ implica maior viés, sendo $\\alpha=0$ o equivalente aos Mínimos Quadrados. Uma solução é a criação de uma terceira partição nos dados, além de treino e teste.\n",
    "\n",
    "Com a primeira achamos o melhor $\\Theta$ dado $\\alpha$, a segunda usamos para definir o $\\alpha$ mais adequado, e a terceira nos dá a medida da qualidade do modelo em si. \n",
    "\n",
    "\n",
    "\n",
    "##### Lasso - Regularização $L_1$\n",
    "\n",
    "De forma semelhante ao **Ridge**, utiliza uma penalidade para os valores dos coeficientes, mas com a norma $l_1$. Sendo assim, este algoritmo costuma achar soluções em que os coeficientes das variáveis menos importantes são zerados. É comum usá-lo para selecionar variáveis.\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 + \\alpha\\sum_{i=0}^{N} |\\theta_i| $$\n",
    "\n",
    "Mesmas observações sobre o novo parâmetro $\\alpha$ no algoritmo anterior.\n",
    "<br>\n",
    "<img src='L1_L2.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=7, n_targets=1, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfx = pd.DataFrame(X, columns=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10'])\n",
    "dfy = pd.DataFrame(y, columns=['y'])\n",
    "df  = pd.concat([dfx, dfy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "Para avaliar a qualidade do modelo, temos a nosso dispor algumas métricas. No caso de regressões, as mais comuns são:\n",
    "\n",
    "#### Variância explicada\n",
    "\n",
    "Como o nome diz, nos dá o quanto o modelo consegue explicar da variação que observamos nos dados:\n",
    "\n",
    "$$ VE(y,\\hat{y}) = 1-\\frac{Var(y-\\hat{y})}{Var(y)}$$\n",
    "\n",
    "#### Erro médio quadrado\n",
    "\n",
    "Média no quadrado da diferença entre real e estimado\n",
    "\n",
    "$$ EMQ = \\frac{\\sum_{j=1}^{M} (y-\\hat{y})^2}{M+1}$$\n",
    "\n",
    "#### Coeficiente de determinação - $R^2$\n",
    "\n",
    "Nos trás o quão bem amostras futuras devem ser estimadas\n",
    "\n",
    "$$ R^2=1-\\frac{\\sum_{j=0}^{M} (y-\\hat{y})^2}{\\sum_{j=0}^{M} (y-\\bar{y})^2}$$\n",
    "\n",
    "Notamos que $R^2$ é númericamente igual à variância explicada.\n",
    "\n",
    "#### R ajustado - $R_{adj}^2$ ou $\\bar{R^2}$\n",
    "\n",
    "O coeficiente de determinação $R^2$ tende a aumentar com a adição de variáveis, independentemente de sua relevância para o modelo. Sendo assim, ao se comparar soluções com número diferente de *inputs*, devemos usar o R ajustado, que tenta controlar esse efeito (M: número de pontos; N: número de variáveis): \n",
    "\n",
    "$$ \\bar{R^2}=1-(1-R^2)\\frac{M-1}{M-N-1}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação\n",
    "\n",
    "Durante a decisão de escolha do modleo, é preciso ter controle da qualidade do que está sendo gerado. Se dependermos somente dos dados com que o algoritmo está treinando, corremos risco de *overfitting*, com muito erro ao se extrapolar para dados além do treino.\n",
    "\n",
    "A solução mais simples é simular dados desconhecidos ao modelo, separando parte da base de treino, a ser usada somente na sua validação.\n",
    "\n",
    "\n",
    "#### Hold-out\n",
    "\n",
    "Método mais simples, dividem-se os dados históricos em *dataset* de treino e de validação. Apesar de se medir a qualidade do *fit* nos dados de treino, as decisões são tomadas com base na validação.\n",
    "\n",
    "<img src=holdout.png>\n",
    "\n",
    "#### Validação cruzada\n",
    "\n",
    "Uma desvantagem do *hold-out* é a limitação que traz em termos de quantidade de pontos em que o modelo será treinado e validado. Se aumentarmos os pontos de treino, teremos menos pontos de validação, e vice-versa.\n",
    "\n",
    "Como alternativa, podemos repetir a divisão treino-teste até passar por toda base de dados, efetuando a validação a cada passo. A performance geral do modelo é obtida da média da performance em cada divisão.\n",
    "\n",
    "<img src=kfold.png>\n",
    "\n",
    "#### Bootstrap (re-amostragem)\n",
    "\n",
    "Com o *bootstrap*, um novo *dataset* é criado a partir de amostragens aleatórias - com reposição - dos dados que já temos.\n",
    "\n",
    "Os dados históricos são entendidos como uma amostra da distribuição real dos dados, e o processo de *bootstrapping* procura recriar esse efeito.\n",
    "\n",
    "<img src=bootstrap.png>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
