{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML](Aula3/ml_def.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente, *machine learning*- ou  aprendizado de máquina - é o estudo que permite automatizar uma tarefa sem a intervenção direta de um humano, usando modelos para extrair as informações de bases de dados.\n",
    "\n",
    "No jargão, o modelo \"treina\" com base nos dados de entrada, e depois \"prevê\" resultados a medida que encontra novas situações.\n",
    "\n",
    "Os modelos podem ser:\n",
    "\n",
    "- Supervisionados: se o treino é realizado com a disponibilidade de variáveis respostas da base de treino\n",
    "- Não-supervisionados: se o próprio algortimo é capaz de extrair as relações relevantes e inferir a variável resposta. Geralmente utilizado em clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos e algoritmos\n",
    "\n",
    "Agora começamos algumas definições úteis\n",
    "\n",
    "- Modelo: entendemos aqui como a formulação matemática que relaciona as variáveis de entrada com a(s) variável(is) de saída. Por exemplo, usaremos mais tarde o modelo $Y = \\omega_0 + \\omega_1 X$, onde X é uma matriz nxm com n pontos de m variáveis.\n",
    "- Algoritmo: o processo matemático e estatítico usado para adequar - *fit* - o modelo aos dados.\n",
    "- Métrica de sucesso: índice que será usado na avaliação da qualidade do resultado. Depende do modelo utilizado\n",
    "- Preprocessamento, ou *data prep*: preparação da base de dados para uso no algoritmo (selecionar/extrair variáveis, tratar valores faltantes, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Overfitting* e *Underfitting*\n",
    "\n",
    "Dois fenômenos, totalmente opostos e igualmente desastrosos, podem ocorrer aos se realizar o *fit* do modelo.\n",
    "\n",
    "- ***Overfitting***: quando o modelo acaba por se adequar *demais* dos dados de treino, como se o algortimo tivesse decorado que tal entrada tem tal saída. Resultados podem estar longe da realidade para pontos não utilizados no *fit*. Dizemos que o modelo tem alta **variância**.\n",
    "- ***Underfitting***: pelo contrário, quando o modelo quase não se adequa aos dados de treino. Dizemos que tem alto **viés**, pois apesar das informações apresentadas, pouco concede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada\n",
    "\n",
    "Uma maneira de contornar os problemas de *over* e *underfitting* é, em primeiro lugar, separar os dados em dois tipos: para treino e para teste. Assim temos maior controle quanto a qualidade do modelo nesse sentido.\n",
    "\n",
    "#### *Overfitting*:\n",
    "\n",
    "- **Característica**: Boa performance no *set* de treino, baixa no de teste.\n",
    "- **Causa**: muitas variáveis, modelo muito complexo\n",
    "- **Solução**: reduzir número de variáveis, regularização\\*, mais pontos\n",
    "\n",
    "#### *Underfitting*\n",
    "\n",
    "- **Característica**: Baixa performance tanto no *set* de treino quanto no de teste\n",
    "- **Causa**: modelo simples demais, muito rígido (regularização\\*)\n",
    "- **Solução**: mais variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Feature Selection*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulação\n",
    "\n",
    "Na regressão linear, representamos a relação entre as variáveis independentes e depentendes no seguinte modelo:\n",
    "\n",
    "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n + \\epsilon$$\n",
    "\n",
    "Ou, de forma matricial\n",
    "\n",
    "$$ y = \\Theta^{\\it{T}}X + \\epsilon$$\n",
    "\n",
    "Onde $\\Theta^{\\it{T}} = [\\theta_0\\hspace{1.5mm}\\theta_1 ... \\theta_n]\\hspace{1mm}$ e $\\hspace{1mm}X = [1\\hspace{1.5mm}x_1 ... x_n]^{\\it{T}}$, e $\\epsilon$ é o erro, que admitimos ter distribuição normal de média 0.\n",
    "\n",
    "Nota-se que o termo **linear** se refere à relação entre os coeficientes. Sendo assim, o modelo $ y = a_1x_1 +a_2x_1^2+ a_3\\log{x_1}$ é linear, pois basta substituir $x_2=x_1^2\\hspace{1mm}$ e $\\hspace{1mm}x_3=\\log{x_1}$\n",
    "\n",
    "#### Algoritmos\n",
    "\n",
    "Como definimos anteriormente, já temos o modelo, agora falta definir como encontrar os coeficientes que mais adequam esse modelo aos nossos dados. Como estamos falando de **modelos supervisionados**, basicamente cada algoritmo tentará minimizar uma **função custo**, que mensiona o quanto os pontos estimados $\\hat{y}$ estão divergentes dos pontos reais $y$.\n",
    "\n",
    "##### Mínimos Quadrados\n",
    "\n",
    "O mais simples dos algortimos, tem como função de custo a soma do quadrado das diferenças entre real e estimado, ou seja:\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 $$\n",
    "\n",
    "Como consequência, o algoritmo se torna relativamente sensível a *outliers*, pontos que por acaso de distanciam do comportamento normal, já que o custo cresce com o quadrado da distância.\n",
    "\n",
    "\n",
    "\n",
    "**COLOCAR MINIMIZAÇÂO? (Derivadas parciais)**\n",
    "\n",
    "##### Ridge - Regularização $L_2$\n",
    "\n",
    "A regularização tem por objetivo limitar a exploração do algoritmo quanto ao espaço de soluções possíveis. No caso do que chamamos de regularização $L_2$, adicionamos o quadrado dos coeficientes à função custo:\n",
    "\n",
    "$$ FC = \\sum_{j=0}^{M} (\\hat{y}_j-y_j)^2 + \\alpha\\sum_{i=0}^{N} |\\theta_i|^2 $$\n",
    "\n",
    "O novo termo enrigece a solução, pois aumentos nos coeficientes serão penalizados, o que aumenta o viés, podendo ser utilizao para remediar o problema de *overfitting*.\n",
    "\n",
    "Porém, mais um parâmetro deve ser definido: o valor de $\\alpha$ que traz o melhor comprometimento viés-variância para a qualidade do modelo - maior $\\alpha$ implica maior viés, sendo $\\alpha=0$ o equivalente aos Mínimos Quadrados. Uma solução é a criação de uma terceira partição nos dados, além de treino e teste.\n",
    "\n",
    "Com a primeira achamos o melhor $\\Theta$ dado $\\alpha$, a segunda usamos para definir o $\\alpha$ mais adequado, e a terceira nos dá a medida da qualidade do modelo em si. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "Para avaliar a qualidade do modelo, temos a nosso dispor algumas métricas. No caso de regressões, as mais comuns são:\n",
    "\n",
    "#### Variância explicada\n",
    "\n",
    "Como o nome diz, nos dá o quanto o modelo consegue explicar da variação que observamos nos dados:\n",
    "\n",
    "$$ VE(y,\\hat{y}) = 1-\\frac{Var(y-\\hat{y})}{Var(y)}$$\n",
    "\n",
    "#### Erro médio quadrado\n",
    "\n",
    "Média no quadrado da diferença entre real e estimado\n",
    "\n",
    "$$ EMQ = \\frac{\\sum_{j=1}^{M} (y-\\hat{y})^2}{M+1}$$\n",
    "\n",
    "#### Coeficiente de determinação - $R^2$\n",
    "\n",
    "Nos trás o quão bem amostras futuras devem ser estimadas\n",
    "\n",
    "$$ R^2=1-\\frac{\\sum_{j=0}^{M} (y-\\hat{y})^2}{\\sum_{j=0}^{M} (y-\\bar{y})^2}$$\n",
    "\n",
    "Notamos que $R^2$ é númericamente igual à variância explicada.\n",
    "\n",
    "### Implantação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
